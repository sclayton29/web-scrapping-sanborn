{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Union List of Sanborn Maps\n",
    "\n",
    "This jupyter notebook will have the code to scrap the list of sandborn maps from the Berkley library website and put them into a CSV format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import requests #Lets us make requests to a website\n",
    "from bs4 import BeautifulSoup #Importing Beautiful Soup for webscraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All links: %s 72\n"
     ]
    }
   ],
   "source": [
    "# saving a website url\n",
    "union_list = \"http://www.lib.berkeley.edu/EART/sanborn_union_list\"\n",
    "\n",
    "r = requests.get(union_list)\n",
    "soup=BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "#Finding all the links on the main page\n",
    "all_links = []\n",
    "for link in soup.findAll('a'):\n",
    "    all_links.append(link.get('href'))\n",
    "print('All links: %s', len(all_links))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.lib.berkeley.edu/EART/sanbul_AL.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_AK.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_AZ.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_AR.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_CA_AB.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_CO.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_CT.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_DE.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_FL.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_GA.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_HI.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_ID.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_IL_A.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_IN.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_IA_AE.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_KS.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_KY_AG.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_LA.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_ME_AL.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_MD.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_MA.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_MI_A.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_MN_AL.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_MS.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_MO_AG.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_MT_AJ.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_NE.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_NV.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_NH.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_NJ_A.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_NM.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_NY_A.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_NC.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_ND.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_OH.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_OK.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_OR_AL.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_PA.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_RI.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_SC.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_SD.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_TN.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_TX_A.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_UT.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_VT.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_VA.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_WA_AL.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_DC.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_WV.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_WI_A.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_WY.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_CDN.html',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_CDN.html#Quebec',\n",
       " 'http://www.lib.berkeley.edu/EART/sanbul_MX.html']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_links = []\n",
    "for link in all_links:\n",
    "    if link is not None:\n",
    "        final_url_element = link.split('/')[-1]\n",
    "    if final_url_element.startswith('sanbul'):\n",
    "        state_links.append(link)\n",
    "        \n",
    "state_links = state_links[0:54]\n",
    "\n",
    "state_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Trying out code using a single\n",
    "\n",
    "#Importing libraries\n",
    "import csv #Lets us write to a csv file\n",
    "import requests #Lets us make requests to a website\n",
    "from bs4 import BeautifulSoup #Importing Beautiful Soup for webscraping\n",
    "\n",
    "#Trying out code for one url\n",
    "state_list = \"http://www.lib.berkeley.edu/EART/sanbul_AK.html\"\n",
    "r = requests.get(state_list)\n",
    "soup_state = BeautifulSoup(r.text, 'html.parser')\n",
    "    \n",
    "#Getting the data in a more workable format\n",
    "html = list(soup_state.children)[2]\n",
    "body = list(html.children)[1]\n",
    "core = list(body.children)\n",
    "\n",
    "string_soup = []\n",
    "for item in core:\n",
    "    string= str(item)\n",
    "    string_soup.append(string)\n",
    "    \n",
    "cities = []\n",
    "dates = []\n",
    "libs = []\n",
    "city = \"\"\n",
    "date = \"\"\n",
    "lib= \"\"\n",
    "\n",
    "for item in string_soup:\n",
    "    if \"city\" in item:\n",
    "        city = item\n",
    "    elif \"date\" in item:\n",
    "        date = item\n",
    "    elif \"class=\\\"lib\\\"\" in item:\n",
    "        lib =item\n",
    "        cities.append(city[16:-4])\n",
    "        dates.append(date[18:-6])\n",
    "        libs.append(lib[17:-6])\n",
    "\n",
    "\n",
    "with open('results.csv','w') as outfile:\n",
    "    rowlists = zip(cities, dates, libs)\n",
    "    writer = csv.writer(outfile)\n",
    "    for row in rowlists:\n",
    "        writer.writerows([row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Trying to use a loop\n",
    "\n",
    "#Importing libraries\n",
    "import csv #Lets us write to a csv file\n",
    "import requests #Lets us make requests to a website\n",
    "from bs4 import BeautifulSoup #Importing Beautiful Soup for webscraping\n",
    "\n",
    "#Creating placeholder lists and variable to use in the loop\n",
    "cities = []\n",
    "dates = []\n",
    "libs = []\n",
    "city = \"\"\n",
    "date = \"\"\n",
    "lib= \"\"\n",
    "states = []\n",
    "\n",
    "for state in state_links:\n",
    "    #parsing the url\n",
    "    if state is not None:\n",
    "        state_list = state\n",
    "        r = requests.get(state_list)\n",
    "        soup_state = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "        #Getting the data in a more workable format\n",
    "        html = list(soup_state.children)[2]\n",
    "        body = list(html.children)[1]\n",
    "        core = list(body.children)\n",
    "        \n",
    "        #Transforming the data to strings - makes next part easier\n",
    "        string_soup = []\n",
    "        for item in core:\n",
    "            string= str(item)\n",
    "            string_soup.append(string)\n",
    "            \n",
    "        #Creating lists of each value\n",
    "        for item in string_soup:\n",
    "            if \"city\" in item:\n",
    "                city = item\n",
    "            elif \"date\" in item:\n",
    "                date = item\n",
    "            elif \"class=\\\"lib\\\"\" in item:\n",
    "                #Doing the appending in the lib level because there will sometimes be multiple libraries for a specific date/city\n",
    "                lib =item\n",
    "                cities.append(city[16:-4])\n",
    "                dates.append(date[18:-6])\n",
    "                libs.append(lib[17:-6])\n",
    "                states.append(state)\n",
    "\n",
    "#Writing out the results as a CSV file\n",
    "with open('results.csv','w') as outfile:\n",
    "    rowlists = zip(states, cities, dates, libs)\n",
    "    writer = csv.writer(outfile)\n",
    "    for row in rowlists:\n",
    "        writer.writerows([row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4290"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4290"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
